#!/usr/bin/env python3
"""
ê¸°ì¡´ MongoDB binary_data ì´ë¯¸ì§€ë¥¼ GridFSë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸

ì‚¬ìš©ë²•:
    python migrate_to_gridfs.py [ì˜µì…˜]

ì˜µì…˜:
    --dry-run       ì‹¤ì œë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜í•˜ì§€ ì•Šê³  ì˜ˆìƒ ê²°ê³¼ë§Œ ì¶œë ¥
    --batch-size N  í•œ ë²ˆì— ì²˜ë¦¬í•  ë¬¸ì„œ ìˆ˜ (ê¸°ë³¸: 50)
    --stats         í˜„ì¬ ì €ì¥ì†Œ í†µê³„ë§Œ ì¶œë ¥

ì˜ˆì‹œ:
    python migrate_to_gridfs.py --dry-run      # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    python migrate_to_gridfs.py                # ì‹¤ì œ ë§ˆì´ê·¸ë ˆì´ì…˜
    python migrate_to_gridfs.py --stats        # í†µê³„ í™•ì¸
"""

import sys
import argparse
from datetime import datetime

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì„¤ì •
sys.path.insert(0, '.')

from utils.gridfs_helper import (
    get_mongo_connection,
    migrate_legacy_to_gridfs,
    get_gridfs_stats
)


def print_stats():
    """ì €ì¥ì†Œ í†µê³„ ì¶œë ¥"""
    stats = get_gridfs_stats()
    
    print("\n" + "=" * 60)
    print("ğŸ“Š ì €ì¥ì†Œ í†µê³„")
    print("=" * 60)
    
    if 'error' in stats:
        print(f"âŒ ì˜¤ë¥˜: {stats['error']}")
        return
    
    print(f"GridFS íŒŒì¼ ìˆ˜: {stats['gridfs_files_count']:,}ê°œ")
    
    total_size_mb = stats['gridfs_total_size'] / (1024 * 1024)
    print(f"GridFS ì´ í¬ê¸°: {total_size_mb:.2f} MB")
    
    print(f"ë ˆê±°ì‹œ ë¬¸ì„œ ìˆ˜: {stats['legacy_count']:,}ê°œ")
    print(f"ë§ˆì´ê·¸ë ˆì´ì…˜ í•„ìš”: {stats['legacy_with_binary']:,}ê°œ (binary_data ìˆëŠ” ë¬¸ì„œ)")
    print("=" * 60 + "\n")


def dry_run_migration():
    """ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œë®¬ë ˆì´ì…˜"""
    gridfs, db, legacy_collection = get_mongo_connection()
    
    if gridfs is None or legacy_collection is None:
        print("âŒ MongoDB ì—°ê²° ì‹¤íŒ¨")
        return
    
    print("\n" + "=" * 60)
    print("ğŸ” ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œë®¬ë ˆì´ì…˜ (Dry Run)")
    print("=" * 60)
    
    # ë§ˆì´ê·¸ë ˆì´ì…˜ ëŒ€ìƒ ë¬¸ì„œ ìˆ˜ í™•ì¸
    to_migrate = legacy_collection.count_documents({'binary_data': {'$exists': True}})
    print(f"ë§ˆì´ê·¸ë ˆì´ì…˜ ëŒ€ìƒ: {to_migrate:,}ê°œ ë¬¸ì„œ")
    
    # ì´ë¯¸ GridFSì— ìˆëŠ” ë¬¸ì„œ í™•ì¸
    already_in_gridfs = 0
    sample_docs = legacy_collection.find(
        {'binary_data': {'$exists': True}},
        {'_id': 1}
    ).limit(100)
    
    for doc in sample_docs:
        if gridfs.exists(doc['_id']):
            already_in_gridfs += 1
    
    print(f"ì´ë¯¸ GridFSì— ì¡´ì¬: ìµœì†Œ {already_in_gridfs}ê°œ (ìƒ˜í”Œ 100ê°œ ì¤‘)")
    print(f"ì˜ˆìƒ ë§ˆì´ê·¸ë ˆì´ì…˜ ìˆ˜: ì•½ {max(0, to_migrate - already_in_gridfs):,}ê°œ")
    
    # ìš©ëŸ‰ ì˜ˆì¸¡
    pipeline = [
        {'$match': {'binary_data': {'$exists': True}}},
        {'$project': {'size': {'$bsonSize': '$binary_data'}}},
        {'$group': {'_id': None, 'total': {'$sum': '$size'}}}
    ]
    result = list(legacy_collection.aggregate(pipeline))
    if result:
        estimated_size_mb = result[0]['total'] / (1024 * 1024)
        print(f"ì˜ˆìƒ ìš©ëŸ‰: ì•½ {estimated_size_mb:.2f} MB")
    
    print("=" * 60)
    print("ğŸ’¡ ì‹¤ì œ ë§ˆì´ê·¸ë ˆì´ì…˜ì„ ì‹¤í–‰í•˜ë ¤ë©´ --dry-run ì˜µì…˜ ì—†ì´ ì‹¤í–‰í•˜ì„¸ìš”.")
    print("=" * 60 + "\n")


def run_migration(batch_size=50):
    """ì‹¤ì œ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰"""
    print("\n" + "=" * 60)
    print("ğŸš€ GridFS ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘")
    print(f"   ë°°ì¹˜ í¬ê¸°: {batch_size}")
    print(f"   ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)
    
    # ë§ˆì´ê·¸ë ˆì´ì…˜ ì „ í†µê³„
    print("\n[ë§ˆì´ê·¸ë ˆì´ì…˜ ì „ í†µê³„]")
    print_stats()
    
    # ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰
    success, fail, skip = migrate_legacy_to_gridfs(batch_size=batch_size)
    
    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "=" * 60)
    print("ğŸ“‹ ë§ˆì´ê·¸ë ˆì´ì…˜ ê²°ê³¼")
    print("=" * 60)
    print(f"âœ… ì„±ê³µ: {success:,}ê°œ")
    print(f"âŒ ì‹¤íŒ¨: {fail:,}ê°œ")
    print(f"â­ï¸ ê±´ë„ˆëœ€: {skip:,}ê°œ (ì´ë¯¸ GridFSì— ì¡´ì¬)")
    print(f"   ì™„ë£Œ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)
    
    # ë§ˆì´ê·¸ë ˆì´ì…˜ í›„ í†µê³„
    print("\n[ë§ˆì´ê·¸ë ˆì´ì…˜ í›„ í†µê³„]")
    print_stats()
    
    if fail > 0:
        print("âš ï¸ ì¼ë¶€ ë¬¸ì„œ ë§ˆì´ê·¸ë ˆì´ì…˜ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    else:
        print("âœ… ë§ˆì´ê·¸ë ˆì´ì…˜ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")


def main():
    parser = argparse.ArgumentParser(
        description='MongoDB binary_dataë¥¼ GridFSë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=__doc__
    )
    
    parser.add_argument(
        '--dry-run',
        action='store_true',
        help='ì‹¤ì œë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜í•˜ì§€ ì•Šê³  ì˜ˆìƒ ê²°ê³¼ë§Œ ì¶œë ¥'
    )
    
    parser.add_argument(
        '--batch-size',
        type=int,
        default=50,
        help='í•œ ë²ˆì— ì²˜ë¦¬í•  ë¬¸ì„œ ìˆ˜ (ê¸°ë³¸: 50)'
    )
    
    parser.add_argument(
        '--stats',
        action='store_true',
        help='í˜„ì¬ ì €ì¥ì†Œ í†µê³„ë§Œ ì¶œë ¥'
    )
    
    args = parser.parse_args()
    
    # MongoDB ì—°ê²° í™•ì¸
    gridfs, db, _ = get_mongo_connection()
    if gridfs is None:
        print("âŒ MongoDB ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        print("   MONGO_URI í™˜ê²½ ë³€ìˆ˜ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        sys.exit(1)
    
    print(f"âœ… MongoDB ì—°ê²° ì„±ê³µ: {db.name}")
    
    if args.stats:
        print_stats()
    elif args.dry_run:
        dry_run_migration()
    else:
        # í™•ì¸ ë©”ì‹œì§€
        print("\nâš ï¸ ì£¼ì˜: ì´ ì‘ì—…ì€ ê¸°ì¡´ ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ GridFSë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜í•©ë‹ˆë‹¤.")
        print("   ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—…ì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
        
        confirm = input("\nê³„ì†í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (yes/no): ")
        if confirm.lower() != 'yes':
            print("ë§ˆì´ê·¸ë ˆì´ì…˜ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            sys.exit(0)
        
        run_migration(batch_size=args.batch_size)


if __name__ == '__main__':
    main()

